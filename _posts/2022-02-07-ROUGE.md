---
layout: post
categories: [Lab]
use_math: true
---

## 개요

ROUGE(Recall-Oriented Understudy for Gisting Evaluation)는 text summarization, machine translation과 같은 generation task를 평가하기 위해 사용되는 대표적인 지표입니다.

## ROUGE에서의 Precision과 Recall

먼저 모델에 의해 생성된 문장과 정답 문장이 있다고 가정해봅시다.

- 생성: `the` `cat` `was` found `under` `the` `bed`
- 정답: `the` `cat` `was` `under` `the` `bed`

겹치는 토큰은 총 6개 입니다.

ROUGE-1 즉 1-gram을 통해 Recall을 계산한다면 다음과 같이 구할 수 있습니다.

$$
\frac{일치하는 1-gram의 \ 수 (생성된 \ sentence 중에서) }{모든 1-gram 쌍 \ (정답 \ sentence 중에서)} = \frac{6}{6} = 1
$$

ROUGE-1의 Precision은 다음과 같습니다.

$$
\frac{일치하는 1-gram의 \ 수 (생성된 \ sentence 중에서) }{모든 1-gram 쌍 \ (생성된 \ sentence 중에서)} = \frac{6}{7}
$$

ROUGE-1의 F-measure은 다음과 같습니다.

$$
{2 \over {1 \over precision} + {1 \over recall}} = {12 \over 13}
$$

ROUGE-L의 경우는 LCS 알고리즘을 통해 구해낸 가장 긴 길이의 sentence를 가지고 계산을 하게 됩니다.

## 참고자료

[참고](https://huffon.github.io/2019/12/07/rouge/)