[ROUGE score](https://huffon.github.io/2019/12/07/rouge/)

[BLEU](https://donghwa-kim.github.io/BLEU.html)

## BLEU score

BLEU(Bilingual Evaluation Understudy) score란 성과지표로 

데이터의 입력 X가 순서정보를 가진 단어들(문장)로 이루어져 있고, 출력 Y 또한 단어들의 시리즈(문장)로 이루어진 경우에 사용됩니다.

- n-gram을 통한 순서쌍들이 얼마나 겹치는지 측정(precision)
- 문장길이에 대한 과적합 보정(Brevity Penalty)
- 같은 단어가 연속적으로 나올때 과적합 되는 것을 보정(Clipping)

$$
BLEU = min(1, \frac{output \ length(예측 \ 문장)}{reference \ length(실제 \ 문장)})(\prod^{4}_{i=1} precision_i)^{\frac{1}{4}}
$$

간단히 보자면 BLEU가 1에 가까울 수록 성능이 좋습니다.

## ROUGE score

ROUGE(Recall-Oriented Understudy for Gisting Evaluation)는 텍스트 요약, 기계 번역 등 자연어 생성 모델의 성능을 평가하기 위한 지표입니다.

구하는 방법은 Recall과 Precision을 통한 F1 스코어값을 계산함으로서 구할 수 있습니다.

다만 ROUGE 뒤에 붙는 문자에 따라 Recall과 Precsion을 측정하는 기준이 달라집니다.

## 배경지식

[n-gram](https://velog.io/@ny_/n-gram)